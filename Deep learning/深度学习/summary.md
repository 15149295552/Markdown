# 总结

## 一、机器学习

### 1. 概述

1）机器学习分类

- 有监督、无监督、半监督
- 基于实例的学习、基于模型的学习

2）机器学习的基本问题

- 回归问题：预测结果为连续值
- 分类问题：预测结果为离散值
- 聚类问题：无监督学习，根据数据相似度，将相似度高的数据划分到同一个聚簇
- 强化学习：最优策略问题，设置奖励、惩罚措施，引导模型超奖励策略发展，避免超惩罚策略发展

3）机器学习的一般过程

收集数据 → 数据清洗 → 标注 → 模型选择 → 训练 → 评估/测试 → 部署应用/维护

### 2. 数据预处理

1）标准化：将每列均值处理为0，标准差处理为1

2）范围缩放：将最小值处理成0，最大值处理成1

3）归一化：将数值转换为0~1之间的相对百分比

4）二值化：将数值转换为0/1中的一个

5）独热编码：将数值表示为一个1和一串0的形式

6）标签编码：将字符串转换为数值

### 3. 回归问题

#### 1）线性回归

- 线性模型：$y = w_1x_1 + w_2x_2 + ... + w_nx_n + b$

- 线性回归：根据样本分布，找一个最优的线性模型，使用该模型执行预测

- 如何找到最优模型

  - 损失函数：度量模型预测值（来自模型计算）和真实值（来自样本）间的偏差

  - 梯度下降：沿着损失函数梯度负方向进行调参，寻找损失函数最小值
    $$
    w_i = w_i + \Delta w_i \\
    \Delta w_i = - \eta \frac{\partial E}{\partial w_i}
    $$
    

#### 2）多项式回归

- 多项式：表达式中包含高次项，多项模型参数是线性的，可以在一定条件下转换为线性回归
- 欠拟合、过拟合
  - 欠拟合：拟合程度不够，模型没有反应出数据变化规律
  - 过拟合：模型过分拟合于数据，导致泛化能力不足
- 欠拟合、过拟合的原因
  - 欠拟合：模型简单、参数太少、特征太少，用简单的模型拟合复杂数据
  - 过拟合：数据太少、模型复杂、参数太多、特征太多，用复杂的模型拟合简单的问题
- 解决欠拟合、过拟合的方法
  - 欠拟合：增加模型复杂度、增加参数、增加特征
  - 过拟合：增加样本数量、简化模型、减少参数、减少特征

#### 3）Lasso回归和岭回归

- Lasso回归：标准备线性回归上增加了L1范式
- 岭回归：标准备线性回归上增加了L2范式

#### 4）决策树

### 4. 分类问题

#### 1）逻辑回归

- 逻辑回归：二分类问题
- 实现方式：前面通过一个回归模型预测一个连续值，然后通过逻辑函数进行离散化处理
- 损失函数：交叉熵
- 利用而分类模型实现多分类：多个二分类模型实现多分类

#### 2）决策树

- 定义：利用树状结构，对属性进行判断，将具有相同属性的数据划分到同一个子节点，最终有一批样本落到同一个叶子节点下，通过投票法产生分类结果，通过求均值产生回归结果
- 如何选择属性：通过信息增益、增益率、基尼系数选择
- 信息熵：反映样本混乱、纯净的指标
- 集成学习算法：讲多个模型集成到一起，克服单个模型的缺陷
  - Boosting：模型有前后强依赖
  - Bagging：模型之间是平行的、并列关系

#### 3）支持向量机

- SVM是一个二分类模型
- 在样本间寻找一个最优分割超平面（线性分类边界）
- 只考虑支持向量（离分类边界最近的样本），支持向量到分类边界的距离最大化（支持向量间隔距离最大化）
- 对于线性不可分问题，通过核函数转换为高纬度空间下的线性可分
- 核函数
  - 线性核函数
  - 多项式核函数
  - 径向基核函数

#### 4）朴素贝叶斯

- 概率相关的概念

  - 概率：随机事件发生的可能性大小，P（A）
  - 联合概率：两个或多个随机事件同时发生的概率，P(A, B ) = P(A)P(B)
  - 条件概率：给定某个条件下，另一个事件发生的概率，P（A|B）
  - 先验概率：没有给定任何前置信息得到的概率
  - 后验概率：在给定一定信息情况下，修正概率

- 贝叶斯定理
  $$
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
  $$

- 朴素贝叶斯：假设条件是独立的，利用贝叶斯定理计算属于每个类别的概率

### 5. 聚类

1）定义：无监督学习，根据样本相似性，将相似度较高的样本划分到同一个群落

2）划分

- 基于原型的聚类：K-Means
- 基于密度的聚类：DBSCAN
- 基于层次的聚类：凝聚层次

3）距离

- 欧氏距离
- 曼哈顿距离
- 闵式距离

4）具体模型

| 对比项             | K-Means          | DBSCAN         | 凝聚层次 |
| ------------------ | ---------------- | -------------- | -------- |
| 类别               | 基于原型         | 基于密度       | 基于层次 |
| 是否提前知道K      | 需要             | 不需要         | 需要     |
| 是否有聚类中心     | 有               | 没有           | 没有     |
| 适合情况           | 适合中心分布明显 | 适合中心不明显 | 均可     |
| 对噪声样本是否敏感 | 敏感             | 不敏感         | 不敏感   |

### 6. 模型评估与优化

1）偏差、方差：偏差衡量预测准不准；方差衡量预测稳定性

2）分类问题评价指标：正确率、错误率、查准率、召回率、F1

3）混淆矩阵

4）交叉验证：数据集较少情况下使用，把数据集划分成K个折叠，每次使用其中一个作为测试集，其它作为训练集，相当于获得了K个不同的数据集

5）超参数评估

- 超参数：提前设置好的参数，不是通过模型训练得来

- 选择方法：网格搜索、随机搜索

  

## 二、深度学习基础

### 1. 感知机、神经网络

1）感知机：又称神经元，接收多个输入，在线性模型计算下产生输出。单个感知机能够处理线性问题（逻辑和/逻辑或），无法处理非线性（例如异或）

2）神经网络：由很多神经元组成的层状结构，每个神经元会和上一层、下一层每个节点相连接，同一层神经元不互相连接，有向无环图。通用近似定理：神经网络只需要一个隐藏层，隐藏层包含足够多的神经元，在激活函数作用下，能够以任意精度模拟任意连续函数

### 2. 激活函数

1）作用：将神经网络的输出由线性转换为非线性

2）常用激活函数

- 阶跃函数
- sigmoid：将负无穷到正无穷范围的值转换0~1之间；连续、平滑、容易求导；梯度消失
- tanh：将负无穷到正无穷范围的值转换-1~1之间；连续、平滑、容易求导；梯度消失。tanh收敛速度比sigmoid更快
- relu：解决了sigmoid梯度消失问题，计算简单
- leaky-relu：relu的变种，小于0的部分给一个很小的梯度
- softmax：将神经网络输出一组数值，转换为百分比，用于神经网络的输出（多分类）

### 3. 损失函数与梯度下降

1）损失函数：度量模型预测值、标签值（真实值）之间的差异，对模型性能进行评估

2）两个常用的损失函数

- 均方差：用于回归问题
- 交叉熵：用于分类问题

3）梯度下降法：对损失函数参数求梯度，使用梯度下降法对参数进行调参（模型优化）

### 4. 反向传播算法

1）作用：求深度神经网络中隐藏层的梯度

2）链式求导法则

### 5. 卷积神经网络

1）卷积：两个函数在某个维度上的叠加

2）卷积神经网络：加入卷积、池化层的神经网络，结构：

输入 → 卷积/激活/池化 → ...... → 全连接

3）各层的作用

- 卷积层：卷积运算，提取特征
- 激活层：激活运算，将线性输出转换为非线性
- 池化层：对数据降维，增加模型的泛化能力
- 全连接层：分类器
- 非标准层：
  - dropout：缓解过拟合
  - Batch Normal：缓解梯度消失，缓解过拟合，增加模型稳定性，加快收敛速度

4）经典卷积神经网络

- LeNet：奠定了CNN的主体结构
- AlexNet：奠定CNN在图像识别领域的地位
- VGG：反复卷积池化
- GoogLeNet：并行卷积
- ResNet：残差结构，缓解深度CNN中的梯度消失问题

## 三、数字图像处理

### 1. 数字图像基础

### 2. 形态变换

### 3. 色彩变换

### 4. 梯度相关

## 四、深度学习图像识别

### 1. 图像分类

### 2. 目标检测

1）定义：检测出图片中有什么物体（分类问题），对物体进行定位（回归x/y/w/h）

2）两个系列

- 两阶段检测：先产生候选区，然后做分类、定位；速度较慢，精度加高
- 一阶段检测：直接在特征图上做分类、定位；速度较快，精度相对较低

3）候选区域产生：滑动窗口法、SS算法（原图像上产生候选区）、RPN网络（特征图上产生候选区）

4）评估指标：分类（查准率、召回率、F1），定位（IOU）

5）多尺度检测与特征融合

6）两阶段检测：R-CNN

7）一阶段检测：YOLO系列

### 3. OCR

1）OCR过程：文字检测、文字识别

2）文字检测模型

- CTPN：适合检测水平文字
- SegLink：适合检测带角度文字

3）文字识别模型：CRNN+CTC

### 4. 图像分割

1）图像分割的本质：对图像中每个像素分类

2）分割粒度：语义分割、实例分割、全景分割

3）图像分割的过程：原图 → 卷积 ..... → 特征图 → 上采样 → 预测出每个像素的类别

4）评价指标：像素精度、平均像素精度、平均交并比

5）经典模型

- FCN：奠定了深度学习领域图像分割的框架
- UNet：适合少量样本下学习、分割
- Mask RCNN：在Faster RCNN增加一组分割输出，实例级分割模型
- DeepLab系列：空洞卷积

# 关于项目问题的总结

1）如何构建数据集？

- 采集（收集）
- 数据清洗
- 数据分类存放，数据标注（分类、目标检测、图像分割标注方式不一样）

2）数据从哪里来？

- 历史交易中发生的、累积的数据（价值最高）
- 采集（项目中很可能自己采集）
- 爬虫
- 使用公共数据集（一般来说价值不高）
- 购买

3）数据量多大？

- 使用深度学习模型，数据越多越好（百量级）
- 数据样本数量不足怎么办：数据增强；采用少量样本性能不错的模型

4）项目采用什么模型，为什么？

- 根据项目需求，以及需求的难易程度，首先选用现有的、经典的、成熟的模型
- 简单的问题首选简单的模型，复杂的问题首选复杂的模型
- 性能相差不大的情况下，首选简单的模型
- 如果不确定选择哪个模型，可以比较、择优使用
- 在实际项目中，可以采用多个模型，发挥各自的特长（集成思想）

5）什么情况下用OpenCV，什么情况下用深度学习？

- OpenCV：样本较少、问题较简单、图像相似度高、场景单一、干扰较少、不需要理解图像内容
- 深度学习：样本数量充足、问题较复杂、干扰较多、场景多变、需要理解图像内容

6）数据如何标注？谁来标注？

- 标注方式：不同的问题采用不同的标注方式
- 标注人员：
  - 大公司：可能有独立的标注团队、标注人员
  - 中小企业：几乎都由项目组成员完成
  - 某些情况下，标注需要专业知识
  - 众包

7）模型训练时间

- 估算
- 项目中采用增量训练

8）训练时采用CPU还是GPU？GPU型号、价格？

- 自己电脑上配置GPU
- 购买云计算设备（按月/年付费、按实际使用小时付费）（查一下阿里云的GPU型号、费用）
- 任务：查阅主流GPU厂商、型号、价格、主要参数
- 类似的问题：用什么工业相机？分辨率？拍摄速度？

9）为什么不采用xxx模型？

- 效果：效果满足项目需求
- 回答出模型的特点（优势、缺点、适用场景）

10）项目准确率是多少？（实际项目中95%以上）

11）模型如何部署、使用？

- 部署方式：服务器部署、客户端部署、嵌入式设备部署
- 形式：封装成网络服务、类、函数

12）项目需要描述清楚的问题

- 项目需求：谁用？用来做什么？解决什么问题、满足什么需求？
- 数据集：来源、数量、预处理方式、标注
- 模型和技术路线选择、优化过程
- 欠拟合、过拟合？处理方式？
- 效果：时间、精度

